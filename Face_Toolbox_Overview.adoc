= Face Toolbox Overview
:showtitle:
:revdate: 2020-03-25

== Overview
There are two categories of face artefacts that can be used for presentation attacks. The first is two-dimensional (2D), such as a printed photo of a target user. The second is three-dimensional (3D), for example, a face mask that mimics the geometry of a user’s face. This toolbox describes 2D and 3D face artefacts  that the evaluator shall create for PAD testing.

There are also two types of face biometric verification methods, 2D or 3D image-based methods. The 2D image-based method captures a two-dimensional face image with a sensor using visible light to recognize a person. The 3D image-based method creates three-dimensional model of the human face using a 3D scanner such as a depth camera.

The evaluator shall refer to this toolbox for the creation of both 2D and 3D face artefacts. However, depending on the type of sensor being used for verification, not all species types may be required as part of the testing. The link:Face_Toolbox_Verification_List.adoc[Face Toolbox Verification List] specifies the types of species that shall be created based on the sensor being evaluated.

== Face Presentation Attacks
=== 2D Attacks
There are many research papers that study face presentation attack, In these papers, researchers typically create 2D face artefacts through the following process.

. Capture face images of a target user using a camera.

. Print the captured image on paper or display the captured image on a screen. This is now referred to as a 2D face artefact.

. Present a 2D face artefact to the TOE.

Presentation attacks with 2D face artefacts can be categorized into the following three types based on the tools or materials used.

* printed photo attack
+
An attacker attempts to spoof the TOE using a captured face image printed on paper

* digital photo attack
+
An attacker attempts to spoof the TOE using a captured face image displayed on a screen

* replay video attack
+
An attacker attempts to spoof the TOE using a recorded face video replayed on a screen

=== 3D Attacks
There are three categories of 3D face artefacts or masks studied in existing research papers. Some papers report successful presentation attacks using the target user’s face with some artefacts (e.g., putting special glasses above the sleeping target user’s face to bypass the attention detection mechanism). This toolbox doesn’t consider such attack scenarios because attack potential required to exploit these scenarios is beyond the Basic attack potential.

- printed face mask
+
Printed photo is bent and worn as a face mask to create the illusion of a real 3D face.

- 3D face mask or mannequin head from 2D face image
+
Predict the 3D features of the face from 2D images and create a 3D face mask or mannequin head from the predicted 3D face image.

- 3D face mask or mannequin head from 3D face image
+
Obtain a 3D face image through a 3D scan of the face or using molding material and create a 3D face mask or mannequin head from the actual 3D image of a target user’s face.

The last category, 3D face mask or mannequin head from 3D face image, is out of scope of this toolbox because it’s beyond the Basic attack potential. As described in <<BIOSD>>, the attack potential shall be rated as follows.

-	*Elapsed time* for *Identification*
+
*⇐ one week* (1)

-	*Window of Opportunity (Access to TOE)* for *Exploitation*
+
*Moderate* (4)

In addition, following factors for creating a 3D face mask or mannequin head from 3D face image should be rated as follows.

-	*Window of Opportunity (Access to Biometric Characteristics)*
+
*Moderate* (4), because 3D scan of the face or using molding material requires direct contact with a target user

-	*Expertise* for *Identification*
+
*Proficient* (2), because using a 3D scanner and 3D printer or using molding material and resin for creating sufficient quality of 3D face mask or head requires some level of knowledge and experiences that the Layman doesn’t have.

In total, the attack potential for 3D face mask or mannequin head from a 3D face image is at least 11, which is beyond the Basic attack potential (10). This is the reason why this toolbox excludes this type of artefacts. However, both printed face mask and 3D face mask or mannequin head 
from 2D face image is within the scope of the Basic attack potential because only 2D images of a target face is required, making the *Window of Opportunity (Access to Biometric Characteristics)* rated as *Immediate* (0).

3D face presentation attack can be conducted through the following process using 3D face mask or mannequin head described above.

. Capture face images of a target user using a camera

*Printed face mask*

[start=2]
. Print captured image on paper

. Wear printed image as a face mask and present it to the TOE

*3D face mask or mannequin head from 2D face image*

[start=2]
. Reconstruct the 3D face from 2D face images and create a 3D face mask or mannequin head

. Wear face mask and present it to the TOE or present the 3D mannequin head to the TOE

== Face Presentation Attack Detection
=== 2D Detection
Images captured by the TOE from the 2D face artefacts may visually look very similar to images captured of a human, however, they are not exactly the same. For example, paper and screens containing the artefacts reflect light in different ways than humans do, because humans are complex non-rigid 3D objects and the artefacts are planar rigid objects. The surface properties of real faces and face artefacts (e.g., pigments) are also different. In addition, face artefacts may contain moiré patterns--an undesired aliasing of images produced during various image display and image acquisition processes. The TOE can detect such differences to detect and prevent presentation attacks.

=== 3D Detection
The 3D face mask or mannequin head may contain quality defects that result in an appearance difference from a genuine human face. For example, the skin texture and detailed facial structures present in a mask or mannequin head have perceivable differences compared to those in real faces. The 3D face mask or mannequin head also may lack the facial motions, such as expression changes, eye blinks, and mouth movements, because it is made of rigid materials. Several PAD methods that utilize such cues have been studied and reported by researchers. Other PAD methods utilize liveness cues, such as thermal signatures, gaze information, and pulse or heartbeat signals, to detect a 3D face mask or mannequin head. However, normally such design information of the PAD is not available to the evaluator and the TOE must be tested in black box manner.

== Common Test Protocol
Face PAD testing can be performed in a variety of ways. The evaluator can use different types of cameras under different illuminations to capture face images of test users to create face artefacts. The evaluator can also present these artefacts under different conditions. It’s not possible to cover all such test scenarios. This toolbox defines a common test protocol to maintain consistency among different PAD testing environments. The evaluator shall follow the test protocols described below, in addition to guidance provided in Toolbox Overview, to conduct the PAD testing.

The tools and media for the creation of artefacts are defined for all tests in the link:Face_Toolbox_Inventory.adoc[Face Toolbox Inventory]. Each attack specifies which tools and media are to be used in the creation of artefacts for that test.

=== Initial Preparation - All Artefacts

. Enrollment
.. The evaluator shall enable face unlock and enroll the test users following instructions provided by the AGD guidance (i.e., test users should not wear glasses, hat, or heavy make-up during the enrolment if the guidance instructs not to do so).
.. The evaluator shall enroll test users’ neutral (i.e., expressionless) frontal faces under the controlled environment where the background of the scene is uniform, the light in the room is switched on, and the window blinds are down (i.e., direct external lighting is blocked). 

. Face image capture
.. The evaluator shall capture face images immediately following the enrolment of test users under identical environmental conditions to reduce the possibility that the artefacts are rejected because differences in illumination, background scene, or expression.
.. The evaluator shall capture test users’ face images with normal and high quality cameras for printed and digital photo attacks. The evaluator shall also record video of the user's face for ten seconds for reply video attacks. 

=== 2D Artefacts - Photos and Video
[start=3]
. Artefact creation
.. The evaluator shall print face images on paper for printed photo attacks, display face images on a screen for digital photo attacks, and replay face videos on a screen for replay video attacks. The size of face images on artefacts shall be same as the test user’s face.

. Artefact presentation
.. The evaluator shall present artefacts to the TOE in the identical controlled environment used during enrollment.
.. The evaluator shall adjust the distance between artefacts and the TOE so that the TOE can’t see the edge of artefacts.
.. The evaluator shall present artefacts in a way that minimizes reflections from ambient lighting.
.. The evaluator shall present artefacts by hand for printed and digital photo attacks, introducing some noticeable motion, and by tripod for replay video attack.

=== 3D Artefacts - Worn Photo Face Mask
[start=3]
. Artefact creation
.. The evaluator shall print face images for printed photo attacks, display face images on a screen for digital photo attacks, and replay them on a screen for replay video attacks. The size of face images on artefacts shall be same as the test user’s face.

. Artefact presentation
.. The evaluator shall bend and wear the printed face mask using tape or paste and present it to the TOE under the identical controlled environment used during enrolment.
.. The evaluator shall present printed face masks in a way that minimizes reflections from ambient lighting.

=== 3D Artefacts - 3D Face Mask or Head from 2D Face Image(s)
[start=3]
. Artefact creation
.. The evaluator shall reconstruct a 3D face from one or more captured 2D face images. 
.. The evaluator shall create a 3D face mask or mannequin head from the 3D image. The size of face mask or mannequin head shall be same as the test user’s face.

. Artefact presentation
.. The evaluator shall wear the 3D face mask and present it to the TOE or present the 3D mannequin head to the TOE under the identical controlled environment used during enrolment.
.. The evaluator shall present the 3D face mask or mannequin head in a way that minimizes reflections from ambient lighting.

== Requirements for Tools
The evaluator needs to use several tools, such as cameras, screens, printers, and media, that meet the specifications listed below, since these specifications impact the clarity or sharpness of face artefacts. For example, the quality of digital photos depends on the screen resolution. If the screen is 4K (i.e., a horizontal screen resolution in the order of 4,000 pixels), and it can provide the finest clarity and detail of face images.

This toolbox defines two level of tools--normal and high quality--to cover variety of tools to conduct the PAD testing efficiently. Not all tools have both levels.

Normal quality tools are inexpensive and can be used by novices to capture and upload images to social media. An attacker may also create face artefacts with such uploaded images without difficulty. Detailed attack methods using uploaded images have been published on the Internet, so the evaluator shall try this type of artefact first. 

High quality tools have better performance (e.g., higher resolution) than normal quality tools.  Such tools should be the latest available (i.e., released at least within one year from the date of PAD testing, or as recent as possible depending on the type of device). Those tools may be expensive, but can be rented at an affordable cost. The reason why such tools should be used is that the PAD algorithm may show good rejection performance for artefacts used to train the algorithm, but reduced rejection performance for artefacts the algorithm has never seen before. Attackers may additionally create high-quality artifacts to maximize the chance of successful attacks.

For 3D printed masks or mannequin heads, if the evaluator outsources the artefact from a third party, the evaluator shall follow the instructions from the third party when capturing photos (e.g., lighting conditions) and provide only a maximum of three photos as source material.

The evaluator shall create such artefacts that with the highest likelihood of bypassing the PAD using the latest tools.

== Test Items
The evaluator shall create artefacts defined in all test items listed in the link:Face_Toolbox_Verification_List.adoc[Face Toolbox Verification List]. The Face Toolbox Verification List specifies the species types that must be created based on the type of biometric sensor.

PAD Toolbox Overview defines required number of attempts for the independent testing and maximum timeframe for both independent and penetration testing.

== Pass/Fail Criteria
If Pass/Fail Criteria is defined in the test items, the evaluator shall follow them. Otherwise, the evaluator shall follow criteria defined in BIOSD and PAD Toolbox Overview.

== Reference Information 
The Face Toolbox was created based on research papers listed in link:Face_Toolbox_References.adoc[Face Toolbox References]. The evaluator should read them before conducting the PAD testing because they include more detailed information about PAD test methods.
